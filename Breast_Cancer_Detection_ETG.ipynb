{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast Cancer Detection - ETG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipOORPxSgAhW"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nSztNHfiIPH"
      },
      "source": [
        "dt = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6rGUBITzC3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f0754-9041-4144-8fb8-8748b9925b43"
      },
      "source": [
        "dt.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAwC_v12GWrE",
        "outputId": "3d660a9e-e55d-4218-930c-ef40bb4633ab"
      },
      "source": [
        "print(dt['DESCR'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVkgoGS-H64d"
      },
      "source": [
        "values = StandardScaler().fit_transform(dt['data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "e1qjk7rjGYj_",
        "outputId": "e2488200-3a42-4353-d083-6b5d33529fa2"
      },
      "source": [
        "pd.DataFrame(values,columns=dt['feature_names'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.097064</td>\n",
              "      <td>-2.073335</td>\n",
              "      <td>1.269934</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>1.568466</td>\n",
              "      <td>3.283515</td>\n",
              "      <td>2.652874</td>\n",
              "      <td>2.532475</td>\n",
              "      <td>2.217515</td>\n",
              "      <td>2.255747</td>\n",
              "      <td>2.489734</td>\n",
              "      <td>-0.565265</td>\n",
              "      <td>2.833031</td>\n",
              "      <td>2.487578</td>\n",
              "      <td>-0.214002</td>\n",
              "      <td>1.316862</td>\n",
              "      <td>0.724026</td>\n",
              "      <td>0.660820</td>\n",
              "      <td>1.148757</td>\n",
              "      <td>0.907083</td>\n",
              "      <td>1.886690</td>\n",
              "      <td>-1.359293</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>2.001237</td>\n",
              "      <td>1.307686</td>\n",
              "      <td>2.616665</td>\n",
              "      <td>2.109526</td>\n",
              "      <td>2.296076</td>\n",
              "      <td>2.750622</td>\n",
              "      <td>1.937015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.829821</td>\n",
              "      <td>-0.353632</td>\n",
              "      <td>1.685955</td>\n",
              "      <td>1.908708</td>\n",
              "      <td>-0.826962</td>\n",
              "      <td>-0.487072</td>\n",
              "      <td>-0.023846</td>\n",
              "      <td>0.548144</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>-0.868652</td>\n",
              "      <td>0.499255</td>\n",
              "      <td>-0.876244</td>\n",
              "      <td>0.263327</td>\n",
              "      <td>0.742402</td>\n",
              "      <td>-0.605351</td>\n",
              "      <td>-0.692926</td>\n",
              "      <td>-0.440780</td>\n",
              "      <td>0.260162</td>\n",
              "      <td>-0.805450</td>\n",
              "      <td>-0.099444</td>\n",
              "      <td>1.805927</td>\n",
              "      <td>-0.369203</td>\n",
              "      <td>1.535126</td>\n",
              "      <td>1.890489</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>-0.430444</td>\n",
              "      <td>-0.146749</td>\n",
              "      <td>1.087084</td>\n",
              "      <td>-0.243890</td>\n",
              "      <td>0.281190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.579888</td>\n",
              "      <td>0.456187</td>\n",
              "      <td>1.566503</td>\n",
              "      <td>1.558884</td>\n",
              "      <td>0.942210</td>\n",
              "      <td>1.052926</td>\n",
              "      <td>1.363478</td>\n",
              "      <td>2.037231</td>\n",
              "      <td>0.939685</td>\n",
              "      <td>-0.398008</td>\n",
              "      <td>1.228676</td>\n",
              "      <td>-0.780083</td>\n",
              "      <td>0.850928</td>\n",
              "      <td>1.181336</td>\n",
              "      <td>-0.297005</td>\n",
              "      <td>0.814974</td>\n",
              "      <td>0.213076</td>\n",
              "      <td>1.424827</td>\n",
              "      <td>0.237036</td>\n",
              "      <td>0.293559</td>\n",
              "      <td>1.511870</td>\n",
              "      <td>-0.023974</td>\n",
              "      <td>1.347475</td>\n",
              "      <td>1.456285</td>\n",
              "      <td>0.527407</td>\n",
              "      <td>1.082932</td>\n",
              "      <td>0.854974</td>\n",
              "      <td>1.955000</td>\n",
              "      <td>1.152255</td>\n",
              "      <td>0.201391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.768909</td>\n",
              "      <td>0.253732</td>\n",
              "      <td>-0.592687</td>\n",
              "      <td>-0.764464</td>\n",
              "      <td>3.283553</td>\n",
              "      <td>3.402909</td>\n",
              "      <td>1.915897</td>\n",
              "      <td>1.451707</td>\n",
              "      <td>2.867383</td>\n",
              "      <td>4.910919</td>\n",
              "      <td>0.326373</td>\n",
              "      <td>-0.110409</td>\n",
              "      <td>0.286593</td>\n",
              "      <td>-0.288378</td>\n",
              "      <td>0.689702</td>\n",
              "      <td>2.744280</td>\n",
              "      <td>0.819518</td>\n",
              "      <td>1.115007</td>\n",
              "      <td>4.732680</td>\n",
              "      <td>2.047511</td>\n",
              "      <td>-0.281464</td>\n",
              "      <td>0.133984</td>\n",
              "      <td>-0.249939</td>\n",
              "      <td>-0.550021</td>\n",
              "      <td>3.394275</td>\n",
              "      <td>3.893397</td>\n",
              "      <td>1.989588</td>\n",
              "      <td>2.175786</td>\n",
              "      <td>6.046041</td>\n",
              "      <td>4.935010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.750297</td>\n",
              "      <td>-1.151816</td>\n",
              "      <td>1.776573</td>\n",
              "      <td>1.826229</td>\n",
              "      <td>0.280372</td>\n",
              "      <td>0.539340</td>\n",
              "      <td>1.371011</td>\n",
              "      <td>1.428493</td>\n",
              "      <td>-0.009560</td>\n",
              "      <td>-0.562450</td>\n",
              "      <td>1.270543</td>\n",
              "      <td>-0.790244</td>\n",
              "      <td>1.273189</td>\n",
              "      <td>1.190357</td>\n",
              "      <td>1.483067</td>\n",
              "      <td>-0.048520</td>\n",
              "      <td>0.828471</td>\n",
              "      <td>1.144205</td>\n",
              "      <td>-0.361092</td>\n",
              "      <td>0.499328</td>\n",
              "      <td>1.298575</td>\n",
              "      <td>-1.466770</td>\n",
              "      <td>1.338539</td>\n",
              "      <td>1.220724</td>\n",
              "      <td>0.220556</td>\n",
              "      <td>-0.313395</td>\n",
              "      <td>0.613179</td>\n",
              "      <td>0.729259</td>\n",
              "      <td>-0.868353</td>\n",
              "      <td>-0.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>2.110995</td>\n",
              "      <td>0.721473</td>\n",
              "      <td>2.060786</td>\n",
              "      <td>2.343856</td>\n",
              "      <td>1.041842</td>\n",
              "      <td>0.219060</td>\n",
              "      <td>1.947285</td>\n",
              "      <td>2.320965</td>\n",
              "      <td>-0.312589</td>\n",
              "      <td>-0.931027</td>\n",
              "      <td>2.782080</td>\n",
              "      <td>0.071025</td>\n",
              "      <td>2.379583</td>\n",
              "      <td>2.604187</td>\n",
              "      <td>1.086384</td>\n",
              "      <td>0.191805</td>\n",
              "      <td>0.666001</td>\n",
              "      <td>2.067178</td>\n",
              "      <td>-1.138416</td>\n",
              "      <td>0.167980</td>\n",
              "      <td>1.901185</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>1.752563</td>\n",
              "      <td>2.015301</td>\n",
              "      <td>0.378365</td>\n",
              "      <td>-0.273318</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>1.629151</td>\n",
              "      <td>-1.360158</td>\n",
              "      <td>-0.709091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1.704854</td>\n",
              "      <td>2.085134</td>\n",
              "      <td>1.615931</td>\n",
              "      <td>1.723842</td>\n",
              "      <td>0.102458</td>\n",
              "      <td>-0.017833</td>\n",
              "      <td>0.693043</td>\n",
              "      <td>1.263669</td>\n",
              "      <td>-0.217664</td>\n",
              "      <td>-1.058611</td>\n",
              "      <td>1.300499</td>\n",
              "      <td>2.260938</td>\n",
              "      <td>1.156857</td>\n",
              "      <td>1.291565</td>\n",
              "      <td>-0.424010</td>\n",
              "      <td>-0.069758</td>\n",
              "      <td>0.252202</td>\n",
              "      <td>0.808431</td>\n",
              "      <td>-0.189161</td>\n",
              "      <td>-0.490556</td>\n",
              "      <td>1.536720</td>\n",
              "      <td>2.047399</td>\n",
              "      <td>1.421940</td>\n",
              "      <td>1.494959</td>\n",
              "      <td>-0.691230</td>\n",
              "      <td>-0.394820</td>\n",
              "      <td>0.236573</td>\n",
              "      <td>0.733827</td>\n",
              "      <td>-0.531855</td>\n",
              "      <td>-0.973978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.702284</td>\n",
              "      <td>2.045574</td>\n",
              "      <td>0.672676</td>\n",
              "      <td>0.577953</td>\n",
              "      <td>-0.840484</td>\n",
              "      <td>-0.038680</td>\n",
              "      <td>0.046588</td>\n",
              "      <td>0.105777</td>\n",
              "      <td>-0.809117</td>\n",
              "      <td>-0.895587</td>\n",
              "      <td>0.184892</td>\n",
              "      <td>-0.257371</td>\n",
              "      <td>0.276693</td>\n",
              "      <td>0.180698</td>\n",
              "      <td>-0.379342</td>\n",
              "      <td>0.661277</td>\n",
              "      <td>0.510827</td>\n",
              "      <td>0.612157</td>\n",
              "      <td>-0.891416</td>\n",
              "      <td>0.036727</td>\n",
              "      <td>0.561361</td>\n",
              "      <td>1.374854</td>\n",
              "      <td>0.579001</td>\n",
              "      <td>0.427906</td>\n",
              "      <td>-0.809587</td>\n",
              "      <td>0.350735</td>\n",
              "      <td>0.326767</td>\n",
              "      <td>0.414069</td>\n",
              "      <td>-1.104549</td>\n",
              "      <td>-0.318409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1.838341</td>\n",
              "      <td>2.336457</td>\n",
              "      <td>1.982524</td>\n",
              "      <td>1.735218</td>\n",
              "      <td>1.525767</td>\n",
              "      <td>3.272144</td>\n",
              "      <td>3.296944</td>\n",
              "      <td>2.658866</td>\n",
              "      <td>2.137194</td>\n",
              "      <td>1.043695</td>\n",
              "      <td>1.157935</td>\n",
              "      <td>0.686088</td>\n",
              "      <td>1.438530</td>\n",
              "      <td>1.009503</td>\n",
              "      <td>-0.173000</td>\n",
              "      <td>2.017716</td>\n",
              "      <td>1.302285</td>\n",
              "      <td>0.785721</td>\n",
              "      <td>0.326634</td>\n",
              "      <td>0.904057</td>\n",
              "      <td>1.961239</td>\n",
              "      <td>2.237926</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>1.653171</td>\n",
              "      <td>1.430427</td>\n",
              "      <td>3.904848</td>\n",
              "      <td>3.197605</td>\n",
              "      <td>2.289985</td>\n",
              "      <td>1.919083</td>\n",
              "      <td>2.219635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>-1.808401</td>\n",
              "      <td>1.221792</td>\n",
              "      <td>-1.814389</td>\n",
              "      <td>-1.347789</td>\n",
              "      <td>-3.112085</td>\n",
              "      <td>-1.150752</td>\n",
              "      <td>-1.114873</td>\n",
              "      <td>-1.261820</td>\n",
              "      <td>-0.820070</td>\n",
              "      <td>-0.561032</td>\n",
              "      <td>-0.070279</td>\n",
              "      <td>0.383092</td>\n",
              "      <td>-0.157449</td>\n",
              "      <td>-0.466152</td>\n",
              "      <td>0.049342</td>\n",
              "      <td>-1.163516</td>\n",
              "      <td>-1.057501</td>\n",
              "      <td>-1.913447</td>\n",
              "      <td>0.752830</td>\n",
              "      <td>-0.382754</td>\n",
              "      <td>-1.410893</td>\n",
              "      <td>0.764190</td>\n",
              "      <td>-1.432735</td>\n",
              "      <td>-1.075813</td>\n",
              "      <td>-1.859019</td>\n",
              "      <td>-1.207552</td>\n",
              "      <td>-1.305831</td>\n",
              "      <td>-1.745063</td>\n",
              "      <td>-0.048138</td>\n",
              "      <td>-0.751207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0       1.097064     -2.073335  ...        2.750622                 1.937015\n",
              "1       1.829821     -0.353632  ...       -0.243890                 0.281190\n",
              "2       1.579888      0.456187  ...        1.152255                 0.201391\n",
              "3      -0.768909      0.253732  ...        6.046041                 4.935010\n",
              "4       1.750297     -1.151816  ...       -0.868353                -0.397100\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564     2.110995      0.721473  ...       -1.360158                -0.709091\n",
              "565     1.704854      2.085134  ...       -0.531855                -0.973978\n",
              "566     0.702284      2.045574  ...       -1.104549                -0.318409\n",
              "567     1.838341      2.336457  ...        1.919083                 2.219635\n",
              "568    -1.808401      1.221792  ...       -0.048138                -0.751207\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzYfQZahGrO_"
      },
      "source": [
        "feature = values\n",
        "df_frt = pd.DataFrame(feature , columns = dt['feature_names'])\n",
        "df_lbl = pd.DataFrame(dt['target'] , columns = ['label'])\n",
        "df = pd.concat([df_frt, df_lbl], axis=1)\n",
        "df = df.sample(frac = 1)\n",
        "\n",
        "feature = df.values[ : , : 30]\n",
        "label = df.values[ : ,30: ]\n",
        "\n",
        "#500 Training\n",
        "X_train = feature[:500]\n",
        "y_train = label[:500]\n",
        "\n",
        "#35 Validation\n",
        "X_val = feature[500:535]\n",
        "y_val = label[500:535]\n",
        "\n",
        "#34 Testing\n",
        "X_test = feature[535:]\n",
        "y_test = label[535:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKQhPmqAGxc6"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation = 'relu', input_dim = 30))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOHzWEVoK1NJ",
        "outputId": "0e1659ca-a7f1-448a-a228-27af9d70d34f"
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=5,epochs=10,validation_data=(X_val,y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 1s 4ms/step - loss: 0.2579 - accuracy: 0.9000 - val_loss: 0.3310 - val_accuracy: 0.8571\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 0.4660 - val_accuracy: 0.8571\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.5858 - val_accuracy: 0.8571\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 0.4400 - val_accuracy: 0.8571\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9880 - val_loss: 0.6952 - val_accuracy: 0.8857\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9900 - val_loss: 0.5737 - val_accuracy: 0.8571\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9900 - val_loss: 0.6978 - val_accuracy: 0.8857\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8571\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.8571\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1424 - val_accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff148a7fdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD-Rh9F7LRDb",
        "outputId": "7c969419-de12-4490-da37-e28e4efb9717"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.060909517109394073, 0.970588207244873]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbYAVKjmLl91",
        "outputId": "7fcca466-2e12-4e6b-b725-17fd953d08c8"
      },
      "source": [
        "j = 0\n",
        "print(\"*\"*20,\"BCD Deep Learning\",\"*\"*20)\n",
        "for i in model.predict(X_val):\n",
        "  print(\"Predicted : \",dt['target_names'][round(float(i))])\n",
        "  print(\"Actual : \",dt['target_names'][int(y_val[j][0])])\n",
        "  print(\"-------------------------\")\n",
        "  j+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  malignant\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  malignant\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n",
            "Predicted :  benign\n",
            "Actual :  benign\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_era5HKEZINA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}